{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd285b2-6238-44d2-8c7c-87cd8fac6250",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**SM339 &#x25aa; Applied Statistics &#x25aa; Spring 2024 &#x25aa; Uhan**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933c830-3439-43d0-8ca2-a58a1beeb13f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Lesson 17. Assessing Multiple Linear Regression Models, cont. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ba9e47-30dc-45e1-9a30-da3c044384f1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## The coefficient of (multiple) determination $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae01c0-feba-4039-9ba7-c5170b2ca0ad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Recall the multiple linear regression model:\n",
    "\n",
    "$$ Y = \\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_k X_k + \\varepsilon \\quad \\text{where} \\quad \\varepsilon \\sim \\text{iid } N(0, \\sigma_{\\varepsilon}^2) $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0245c284-9b31-4451-8c3c-49e9ad95058d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Question: __How much of the variation in $Y$ is explained by the model?__\n",
    "\n",
    "- Formula:\n",
    "\n",
    "$$ R^2 = \\frac{\\text{variability explained by model}}{\\text{total variability in $Y$}} = \\frac{\\mathit{SSModel}}{\\mathit{SSTotal}} = 1 - \\frac{\\mathit{SSE}}{\\mathit{SSTotal}} $$\n",
    "\n",
    "- Interpretation:\n",
    "\n",
    "    - Suppose we fit a multiple linear regression model and the $R^2$ value is 0.75\n",
    "    \n",
    "    - Then we would say\n",
    "        > The linear regression model with explanatory variables <mark>list of explanatory variables</mark> explains 75% of the variability in the response variable <mark>response variable</mark>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a032b93-79c1-4681-a96b-c90a4fe699a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Things to note:\n",
    "\n",
    "    - We call $R^2$ the coefficient of _multiple_ determination because we now have multiple predictors\n",
    "    \n",
    "    - For simple linear regression, we use $r^2$ (with lowercase $r$) to denote the coefficient of determination because it was the sample correlation $r$ between $X$ and $Y$ squared\n",
    "    \n",
    "    - That interpretation does not translate directly to the case with multiple predictors, since each predictor has its own correlation with the response variable\n",
    "    \n",
    "    - However, in the multiple linear regression setting, if we calculate the correlation between $y$ (observed) and $\\hat{y}$ (fitted) and then square that correlation, we would obtain $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e128dd54-a30e-422c-a88d-514a4782b1d1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62d15e8-7c7d-4d07-b556-22bd167a7ba8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Continuing with the `RailsTrails` example from the previous lesson..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de569214-faf9-4ec7-ab75-8f7d74551659",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(Stat2Data)\n",
    "data(RailsTrails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dec1f78-0001-45e4-9f0c-598b00a5c915",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### a.\n",
    "How much of the variability in $\\mathit{Price2014}$ is explained by the _simple_ linear regression model with _only_ $\\mathit{SquareFeet}$ as the predictor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0552022-2ef6-4528-ad9c-ec79032a1d95",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73f5955f-48be-46f5-a811-9f6c6c745e5f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "*Write your notes here. Double-click to edit.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d9215-40c4-4a77-81a8-736a47bbb0d5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### b.\n",
    "How much of the variability in $\\mathit{Price2014}$ is explained by the _simple_ linear regression model with _only_ $\\mathit{Distance}$ as the predictor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca9c23-ac53-4295-8994-3a640af36d55",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efec401c-a9ff-4f42-a029-b454331ae9dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "*Write your notes here. Double-click to edit.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e9e999-91ba-4eaa-b9ae-2ed14a0b6430",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### c.\n",
    "How much of the variability in  $\\mathit{Price2014}$ is explained by the _multiple_ linear regression model with both $\\mathit{SquareFeet}$ and $\\mathit{Distance}$ as predictors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635ddc5-399d-47e7-9fff-8e4364e63bc7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8476c34c-1bdf-467d-81c7-dadd68324cd2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "*Write your notes here. Double-click to edit.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3037e0-05e5-4878-9983-b097b15a4256",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## The adjusted coefficient of determination (adjusted $R^2$) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8cf3c8-187e-4b48-b11a-209b94889c89",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Adding an additional predictor to a multiple linear regression model can _never_ decrease the percentage of variability explained by that model, assuming we are using the same data\n",
    "\n",
    "- __But... is the increase in explained variability due to important new information in the new predictor, or is it just due to chance?__\n",
    "\n",
    "- One way to answer this question is to do a $t$-test for the new predictor's coefficient, like we did in the previous lesson\n",
    "\n",
    "- Another less formal option is to look at the __adjusted $R^2$__, denoted by $R_{adj}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcbb121-f6e3-432b-941d-79bd9711ef4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- The __adjusted coefficient of determination $R_{adj}^2$__ accounts for\n",
    "    \n",
    "    1. the amount of variability explained by the model, __and__\n",
    "    \n",
    "    2. the number of predictors\n",
    "    \n",
    "- It includes a _penalty_ for additional predictors, so an extra predictor has to help _enough_ in order to raise $R_{adj}^2$\n",
    "\n",
    "- $R_{adj}^2$ can go _up or down_ when a new predictor is included\n",
    "\n",
    "- Therefore, $R_{adj}^2$ is a good way to capture models with different numbers of predictors\n",
    "    - It's most useful to quickly compare lots of models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a352f092-45b4-4f1c-915b-9c6146ddf218",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Formula:\n",
    "    $$R_{adj}^2 = 1 - \\frac{\\hat{\\sigma}_{\\varepsilon}^2}{s_{Y}^2} = 1 - \\frac{ \\mathit{SSE} \\,/\\, (n - (k + 1)) }{ \\mathit{SSTotal} \\,/\\, (n - 1) } $$\n",
    "    \n",
    "    - $s_{Y}^2$ is the sample variance of $Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95d72d7-b0cf-4935-bb99-773a1b32e143",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b24171-0a10-40a0-ad48-45168e5067d4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Continuing with the `RailsTrails` example..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87c17ab-618a-482a-96c9-7fc12e2bb708",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### a.\n",
    "For our two predictor model of house prices, what is $R^2_{adj}$? Look for \"Adjusted R-squared\" in the Example 1 output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ff7bb-dfab-45b5-88ed-03b5ff128919",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "*Write your answer here. Double-click to edit.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fdd98e-087f-4dea-9e9f-e2495e49e062",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### b.\n",
    "What is $R_{adj}^2$ for the simple linear regression model using only $\\mathit{SquareFeet}$ as a predictor of $\\mathit{Price2014}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c01669d-c8a2-4b6b-817a-078f6f0b0b2f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "*Write your answer here. Double-click to edit.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0e3d28-536f-47cb-8eb0-c8832b7ccca3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### c.\n",
    "Based on your answers above, which model seems to be better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06531bca-2403-4511-a771-3b8c8fd00c46",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "*Write your answer here. Double-click to edit.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f9bed7-fa82-436c-91e4-8925bcc81929",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Confidence and prediction intervals for response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09aad98-0340-4d58-a632-1afa23c6ff7c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Like with simple linear regression, we often would like to use our multiple linear regression model to make predictions\n",
    "\n",
    "- We may want to predict:\n",
    "\n",
    "    - The __mean response__ for a particular set of predictor values\n",
    "    \n",
    "    - A future __individual response__ for a particular set of predictor values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4633a5f3-4e11-40b1-8e45-673e8ee44f04",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Confidence interval for response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f78a1978-de63-41b7-bd58-75529b4ddf64",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- To estimate the mean of $Y$ when $X_1 =x_1^*$, $X_2 = x_2^*$, etc.,  we use a __$100(1 - \\alpha)$% confidence interval__ for $\\mu_Y$:\n",
    "\n",
    "$$\\hat{y} \\pm t_{\\alpha / 2, n - (k + 1)} \\mathit{SE}_{\\hat{\\mu}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f24988-d740-4e42-9774-828ead7bd1b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Interpretation:\n",
    "    > We are <mark>$100(1 - \\alpha)$%</mark> confident that the average <mark>response</mark> for all <mark>observational units</mark> with <mark>predictor values $x_1^*, \\dots, x_k^*$</mark> is between <mark>lower endpoint of CI</mark> and <mark>upper endpoint of CI</mark> <mark>units</mark>\n",
    "\n",
    "    - Rephrase the highlighted parts so that it matches the context of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fe940b-145d-4819-9014-072e20796f37",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- This means that, with repeated construction and use, the procedure of forming a CI will capture the true $\\mu_Y$ for the predictor values $x_1^*, \\dots, x_k^*$ $100(1 - \\alpha)$% of the time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac50b4a-059f-4f3b-8acb-28696b54630e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80f0c8e-180f-488e-999a-c10f939c6378",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Continuing with the `RailsTrails` example..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeb2b5c-c575-470e-85c7-85777a5f256f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### a.\n",
    "Use the fitted model equation directly to predict the price (in 2014) of a home that is 1800 square feet and 1.2 miles from a bike trail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f6f98-9ee9-4165-98b7-3f6bda4a0c2f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "*Write your notes here. Double-click to edit.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d5cf0-63e4-4595-af45-e3f11ce901a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### b.\n",
    "Construct and interpret a 90% confidence interval for the __average__ price of all 1800 square foot houses that are 1.2 miles from a bike trail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70638d41-d1f7-4b5c-83bf-7a438884bf10",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d2b9b47-0816-46bb-b549-8e4de6c1edc8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "*Write your notes here. Double-click to edit.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020274ea-a235-4463-ad67-743149efa336",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Prediction interval for response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d0ac48e-46de-436b-9222-5c16cfd62d6f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- To estimate a future individual response $y$ when $X_1 =x_1^*$, $X_2 = x_2^*$, etc.,  we use a __$100(1 - \\alpha)$% prediction interval__ for $\\hat{y}$:\n",
    "\n",
    "$$ \\hat{y} \\pm t_{\\alpha/2, n - (k + 1)} \\mathit{SE}_{\\hat{y}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c682939-54ef-4658-b6d6-2e45ce0ab18c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Interpretation:\n",
    "    > We are <mark>$100(1 - \\alpha)$%</mark> confident that the <mark>response</mark> of a particular <mark>observational unit</mark> with <mark>predictor values $x_1^*, \\dots, x_k^*$</mark> is between <mark>lower endpoint of CI</mark> and <mark>upper endpoint of CI</mark> <mark>units</mark>\n",
    "\n",
    "    - Rephrase the highlighted parts so that it matches the context of the problem "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4990d146-5d21-4775-87e9-2065bcdc6145",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- This means that, with repeated construction and use, the procedure of forming a PI will capture the actual $y$ for the predictor values $x_1^*, \\dots, x_k^*$ $100(1 - \\alpha)$% of the time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5014d58b-2a1d-4882-96fe-2b38436b7044",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Example 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37e5f47-b068-4a8d-842b-5e764c8c4f7a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Continuing with the `RailsTrails` example..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27b4617-23f9-4fc2-8719-8b158d2246f8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### a.\n",
    "Construct and interpret a 90% interval predicting the price of one particular 1800 square foot house that is 1.2 miles from a bike trail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47eaa2f-d3bc-40c3-860a-2f98ce5cfe5b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d06d81e-d7d8-4d31-8e4e-1c3927e5b0b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "*Write your notes here. Double-click to edit.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdd0185-0ba4-4ade-892f-121d9ba65a8a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### b.\n",
    "Which is wider, the 90% CI or the 90% PI?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75171204-28d8-41c7-9539-de2119d0b572",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "*Write your notes here. Double-click to edit.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d780e36-66ce-4015-b6cf-5d1b9b35e517",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Notes about confidence intervals vs. prediction intervals for response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6317356-ffb1-46b6-ad7c-8a4a9c6ed5dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- The point estimate anchoring both intervals is the same: $\\hat{y}$\n",
    "\n",
    "- The prediction interval is always wider than the confidence interval, because the prediction interval uses a larger standard error $\\mathit{SE}_{\\hat{y}}$\n",
    "\n",
    "- Intuitively: \n",
    "    - The PI captures more uncertainty \n",
    "    \n",
    "    - In addition to uncertainty due to sampling, the PI also captures the inherent uncertainty in the response of an _individual_ data point"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
